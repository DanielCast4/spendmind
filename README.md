# ğŸ’° Personal Expense Manager (API)

Backend project developed with **Python, FastAPI, SQLAlchemy, and MySQL/PostgreSQL** for managing, analyzing, and visualizing personal expenses.

This project goes beyond a traditional CRUD: it includes **advanced SQL queries**, **automatic textual insights**, and **charts generated directly from the API**, making it ideal as a portfolio project.

---

## ğŸš€ Main Features

* âœ… Category CRUD
* âœ… Expense CRUD
* âœ… Filtered queries (by date, category, amount)
* âœ… Aggregated SQL reports
* âœ… Automatic insights in natural language
* âœ… Expense charts (matplotlib)
* âœ… Bulk fake data generation for testing

---

## ğŸ§  Automatic Insights Examples

The API can generate dynamic conclusions such as:

* ğŸ“ˆ Highest spending month
* ğŸ“‰ Lowest spending month
* ğŸ”¥ Most impactful category
* ğŸ  Percentage of expenses spent on rent
* ğŸ“Š Overall spending trend

All insights are calculated dynamically from the data stored in the database.

---

## ğŸ“Š Available Charts

The API can generate charts directly as PNG images:

* Monthly expense evolution
* Easily extensible to category breakdowns, comparisons, etc.

Example endpoint:

```http
GET /charts/monthly-expenses
```

---

## ğŸ—ï¸ Project Architecture

```
app/
 â”œâ”€â”€ database/
 â”‚   â”œâ”€â”€ connection.py
 â”‚   â””â”€â”€ models.py
 â”‚   
 â”œâ”€â”€ routers/
 â”‚   â”œâ”€â”€ insights.py
 â”‚   â””â”€â”€ charts.py
 â”œâ”€â”€ routers/
 â”‚   â”œâ”€â”€ categories.py
 â”‚   â”œâ”€â”€ expenses.py
 â”‚   â””â”€â”€ reports.py
 â”œâ”€â”€ schemas/
 â”‚   â”œâ”€â”€ categories.py
 â”‚   â”œâ”€â”€ expenses.py
 â”‚   â”œâ”€â”€ insights.py
 â”‚   â””â”€â”€ reports.py
 â”œâ”€â”€ services/
 â”‚   â””â”€â”€ insights_service.py
 â””â”€â”€ main.py

scripts/
 â””â”€â”€ generate_expenses.py
```

---

## ğŸ› ï¸ Tech Stack

* **Python 3.10+**
* **FastAPI**
* **SQLAlchemy ORM**
* **SQLite / PostgreSQL / MySQL** (compatible)
* **Matplotlib**
* **Pydantic**

---

## ğŸ—„ï¸ Database Setup (PostgreSQL)

This project was tested with PostgreSQL. Follow these steps to create the database:

### 1ï¸âƒ£ Install PostgreSQL

* **Linux (Ubuntu):**

```bash
sudo apt update
sudo apt install postgresql postgresql-contrib
```

* **Mac (Homebrew):**

```bash
brew install postgresql
brew services start postgresql
```

* **Windows:**
  Download the installer from [PostgreSQL official site](https://www.postgresql.org/download/windows/).

### 2ï¸âƒ£ Create a database and user

```sql
-- Login to PostgreSQL
psql -U postgres

-- Create database
CREATE DATABASE expense_manager;

-- Create user (replace 'password' with a secure password)
CREATE USER expense_user WITH PASSWORD 'password';

-- Give privileges
GRANT ALL PRIVILEGES ON DATABASE expense_manager TO expense_user;

-- Exit
\q
```

### 3ï¸âƒ£ Configure connection

Edit `app/database/connection.py` file with your **secure password**:

```python
DATABASE_URL = "postgresql+psycopg2://expense_user:password@localhost/expense_manager"
```

### 4ï¸âƒ£ Create tables (if using SQLAlchemy `Base.metadata.create_all`)

```python
from app.database.connection import engine
from app.database.base import Base

Base.metadata.create_all(bind=engine)
```

Your PostgreSQL database is now ready.

---

## â–¶ï¸ Installation & Running

### 1ï¸âƒ£ Clone the repository

```bash

```

### 2ï¸âƒ£ Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the application

```bash
uvicorn app.main:app --reload
```

Access the interactive API docs: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ§ª Populate the database with test data

The project includes a script to generate realistic random expenses:

```
python -m scripts.generate_expenses   
```

This will automatically insert hundreds of records for testing and analysis.

---

## ğŸ¯ Project Goal

This project demonstrates skills in:

* Professional backend development
* REST API design
* Advanced SQL and aggregations
* Business logic
* Data analysis
* Visualization

---

## ğŸ”® Possible Future Improvements

* Frontend dashboard (React + Chart.js)
* Report export (CSV / PDF)
* Automatic spending alerts
* User authentication
* Cloud deployment

---
